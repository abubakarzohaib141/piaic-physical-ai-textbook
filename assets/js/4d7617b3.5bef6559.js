"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[9409],{2460:(e,a,n)=>{n.r(a),n.d(a,{contentTitle:()=>o,default:()=>p,frontMatter:()=>t,metadata:()=>s,toc:()=>l});var i=n(8168),r=(n(6540),n(5680));const t={},o="Module 3: The AI-Robot Brain - NVIDIA Isaac",s={unversionedId:"physical-ai/module3-isaac/overview",id:"physical-ai/module3-isaac/overview",isDocsHomePage:!1,title:"Module 3: The AI-Robot Brain - NVIDIA Isaac",description:"Overview",source:"@site/docs/physical-ai/module3-isaac/overview.md",sourceDirName:"physical-ai/module3-isaac",slug:"/physical-ai/module3-isaac/overview",permalink:"/piaic-physical-ai-textbook/docs/physical-ai/module3-isaac/overview",editUrl:"https://github.com/abubakarzohaib141/piaic-physical-ai-textbook/edit/main/docs/docs/physical-ai/module3-isaac/overview.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Navigation with Nav2",permalink:"/piaic-physical-ai-textbook/docs/physical-ai/module3-isaac/navigation"},next:{title:"Module 4: Vision-Language-Action (VLA)",permalink:"/piaic-physical-ai-textbook/docs/physical-ai/module4-vla/overview"}},l=[{value:"Overview",id:"overview",children:[]},{value:"Why NVIDIA Isaac for Humanoid Robots?",id:"why-nvidia-isaac-for-humanoid-robots",children:[]},{value:"Isaac Sim - The Digital Twin on Steroids",id:"isaac-sim---the-digital-twin-on-steroids",children:[{value:"Installation",id:"installation",children:[]},{value:"Key Features",id:"key-features",children:[]},{value:"Loading a Humanoid in Isaac Sim",id:"loading-a-humanoid-in-isaac-sim",children:[]}]},{value:"Isaac ROS - Hardware-Accelerated Perception",id:"isaac-ros---hardware-accelerated-perception",children:[{value:"Architecture",id:"architecture",children:[]},{value:"Key Packages",id:"key-packages",children:[]}]},{value:"Isaac Gym - Massively Parallel RL",id:"isaac-gym---massively-parallel-rl",children:[{value:"Training Humanoid Walking",id:"training-humanoid-walking",children:[]}]},{value:"Synthetic Data Generation",id:"synthetic-data-generation",children:[]},{value:"Sim-to-Real Transfer",id:"sim-to-real-transfer",children:[{value:"Domain Randomization",id:"domain-randomization",children:[]}]},{value:"Cloud Deployment",id:"cloud-deployment",children:[]},{value:"Best Practices",id:"best-practices",children:[]},{value:"Next Steps",id:"next-steps",children:[]},{value:"Resources",id:"resources",children:[]}],c={toc:l},m="wrapper";function p({components:e,...a}){return(0,r.yg)(m,(0,i.A)({},c,a,{components:e,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"module-3-the-ai-robot-brain---nvidia-isaac"},"Module 3: The AI-Robot Brain - NVIDIA Isaac"),(0,r.yg)("h2",{id:"overview"},"Overview"),(0,r.yg)("p",null,"NVIDIA Isaac is the industry-leading platform for developing, testing, and deploying AI-powered robots. It provides:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Isaac Sim"),": Photorealistic physics simulation"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Isaac ROS"),": Hardware-accelerated perception and navigation"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Isaac Gym"),": Massively parallel reinforcement learning"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Omniverse"),": Collaborative 3D workflow platform")),(0,r.yg)("h2",{id:"why-nvidia-isaac-for-humanoid-robots"},"Why NVIDIA Isaac for Humanoid Robots?"),(0,r.yg)("p",null,"Traditional robotics pipelines are CPU-bound and struggle with:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Real-time computer vision (30+ FPS)"),(0,r.yg)("li",{parentName:"ul"},"SLAM with high-resolution sensors"),(0,r.yg)("li",{parentName:"ul"},"Multi-robot simulation at scale")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Isaac leverages GPU acceleration")," to achieve:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"\u2705 ",(0,r.yg)("strong",{parentName:"li"},"10-100x faster")," perception vs. CPU"),(0,r.yg)("li",{parentName:"ul"},"\u2705 ",(0,r.yg)("strong",{parentName:"li"},"Photorealistic rendering")," for sim-to-real transfer"),(0,r.yg)("li",{parentName:"ul"},"\u2705 ",(0,r.yg)("strong",{parentName:"li"},"Thousands of parallel environments")," for RL training"),(0,r.yg)("li",{parentName:"ul"},"\u2705 ",(0,r.yg)("strong",{parentName:"li"},"RTX ray tracing")," for accurate sensor simulation")),(0,r.yg)("h2",{id:"isaac-sim---the-digital-twin-on-steroids"},"Isaac Sim - The Digital Twin on Steroids"),(0,r.yg)("h3",{id:"installation"},"Installation"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"# Download Omniverse Launcher\n# https://www.nvidia.com/en-us/omniverse/download/\n\n# Install Isaac Sim from Omniverse Launcher\n# Version: 2023.1.1 or later\n\n# Install ROS 2 bridge\nsudo apt install ros-humble-isaac-ros-common\n")),(0,r.yg)("h3",{id:"key-features"},"Key Features"),(0,r.yg)("h4",{id:"1-usd-universal-scene-description"},"1. USD (Universal Scene Description)"),(0,r.yg)("p",null,"Isaac Sim uses Pixar's USD format for scenes:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'from pxr import Usd, UsdGeom, Gf\n\n# Create a scene\nstage = Usd.Stage.CreateNew("humanoid_scene.usd")\n\n# Add a sphere (head)\nsphere = UsdGeom.Sphere.Define(stage, "/World/head")\nsphere.GetRadiusAttr().Set(0.15)\nsphere.AddTranslateOp().Set(Gf.Vec3f(0, 0, 1.7))\n\n# Save\nstage.Save()\n')),(0,r.yg)("h4",{id:"2-physx-physics-engine"},"2. PhysX Physics Engine"),(0,r.yg)("p",null,"NVIDIA PhysX provides real-time physics with:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Articulation solver for robotic joints"),(0,r.yg)("li",{parentName:"ul"},"Contact and friction simulation"),(0,r.yg)("li",{parentName:"ul"},"Soft body dynamics"),(0,r.yg)("li",{parentName:"ul"},"GPU-accelerated cloth simulation")),(0,r.yg)("h4",{id:"3-rtx-rendering"},"3. RTX Rendering"),(0,r.yg)("p",null,"Enables photorealistic sensor simulation:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Ray-traced lighting and shadows"),(0,r.yg)("li",{parentName:"ul"},"Accurate depth and semantic segmentation"),(0,r.yg)("li",{parentName:"ul"},"Material properties (metallic, transparent, etc.)")),(0,r.yg)("h3",{id:"loading-a-humanoid-in-isaac-sim"},"Loading a Humanoid in Isaac Sim"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'from omni.isaac.kit import SimulationApp\n\n# Initialize\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.robots import Robot\nfrom omni.isaac.core.utils.prims import create_prim\n\n# Create world\nworld = World()\nworld.scene.add_default_ground_plane()\n\n# Load humanoid from USD\nrobot = Robot(\n    prim_path="/World/humanoid",\n    name="my_humanoid",\n    usd_path="/path/to/humanoid.usd"\n)\n\n# Add to scene\nworld.scene.add(robot)\n\n# Reset and play\nworld.reset()\nwhile simulation_app.is_running():\n    world.step(render=True)\n\nsimulation_app.close()\n')),(0,r.yg)("h2",{id:"isaac-ros---hardware-accelerated-perception"},"Isaac ROS - Hardware-Accelerated Perception"),(0,r.yg)("h3",{id:"architecture"},"Architecture"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-mermaid"},"graph LR\n    A[Camera/Sensor] --\x3e B[Isaac ROS GEM]\n    B --\x3e C[GPU Processing]\n    C --\x3e D[ROS 2 Topic]\n    D --\x3e E[Navigation/Planning]\n")),(0,r.yg)("h3",{id:"key-packages"},"Key Packages"),(0,r.yg)("h4",{id:"1-isaac-ros-visual-slam"},"1. Isaac ROS Visual SLAM"),(0,r.yg)("p",null,"Real-time VSLAM using GPU:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"# Install\nsudo apt install ros-humble-isaac-ros-visual-slam\n\n# Launch\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py\n")),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"# Configuration\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam',\n            parameters=[{\n                'denoise_input_images': True,\n                'rectified_images': True,\n                'enable_imu_fusion': True,\n                'gyro_noise_density': 0.000244,\n                'gyro_random_walk': 0.000019393,\n                'accel_noise_density': 0.001862,\n                'accel_random_walk': 0.003,\n            }],\n            remappings=[\n                ('stereo_camera/left/image', '/humanoid/camera/left/image_raw'),\n                ('stereo_camera/right/image', '/humanoid/camera/right/image_raw'),\n                ('visual_slam/imu', '/humanoid/imu'),\n            ]\n        )\n    ])\n")),(0,r.yg)("h4",{id:"2-isaac-ros-dnn-inference"},"2. Isaac ROS DNN Inference"),(0,r.yg)("p",null,"Hardware-accelerated deep learning:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"# Object detection with DOPE (Deep Object Pose Estimation)\nros2 launch isaac_ros_dope isaac_ros_dope_tensor_rt.launch.py\n")),(0,r.yg)("h4",{id:"3-isaac-ros-depth-segmentation"},"3. Isaac ROS Depth Segmentation"),(0,r.yg)("p",null,"Semantic segmentation from depth:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"# Process depth image\nfrom isaac_ros_depth_segmentation import DepthSegmentationNode\n\nclass HumanoidPerception(Node):\n    def __init__(self):\n        super().__init__('perception')\n        \n        # Subscribe to depth\n        self.depth_sub = self.create_subscription(\n            Image,\n            '/humanoid/camera/depth',\n            self.depth_callback,\n            10\n        )\n        \n        # Publish segmented obstacles\n        self.obstacle_pub = self.create_publisher(\n            PointCloud2,\n            '/perception/obstacles',\n            10\n        )\n")),(0,r.yg)("h2",{id:"isaac-gym---massively-parallel-rl"},"Isaac Gym - Massively Parallel RL"),(0,r.yg)("p",null,"Train policies with thousands of parallel environments:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'from isaacgym import gymapi, gymutil\n\n# Create gym instance\ngym = gymapi.acquire_gym()\n\n# Create simulation\nsim_params = gymapi.SimParams()\nsim_params.use_gpu_pipeline = True\nsim = gym.create_sim(0, 0, gymapi.SIM_PHYSX, sim_params)\n\n# Create 4096 parallel environments\nnum_envs = 4096\nenvs_per_row = int(np.sqrt(num_envs))\n\nfor i in range(num_envs):\n    env = gym.create_env(sim, lower, upper, envs_per_row)\n    # Load humanoid asset\n    asset = gym.load_asset(sim, asset_root, asset_file)\n    actor = gym.create_actor(env, asset, pose, f"humanoid_{i}", i, 0)\n    \n# Simulate\nwhile True:\n    gym.simulate(sim)\n    gym.fetch_results(sim, True)\n    gym.step_graphics(sim)\n    gym.render_all_camera_sensors(sim)\n')),(0,r.yg)("h3",{id:"training-humanoid-walking"},"Training Humanoid Walking"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"import torch\nimport torch.nn as nn\n\nclass HumanoidPolicyNetwork(nn.Module):\n    def __init__(self, obs_dim, act_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(obs_dim, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, act_dim)\n        \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        return torch.tanh(self.fc3(x))\n\n# Observations: joint positions, velocities, IMU\n# Actions: joint torques\nobs_dim = 37  # 12 joints * 2 + IMU (9) + base velocity (4)\nact_dim = 12  # 12 joint torques\n\npolicy = HumanoidPolicyNetwork(obs_dim, act_dim).cuda()\n\n# Train with PPO, SAC, etc.\n")),(0,r.yg)("h2",{id:"synthetic-data-generation"},"Synthetic Data Generation"),(0,r.yg)("p",null,"Generate training data for computer vision:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'from omni.isaac.synthetic_utils import SyntheticDataHelper\n\n# In Isaac Sim\nsd_helper = SyntheticDataHelper()\n\n# Enable RGB, depth, semantic segmentation, instance segmentation\nsd_helper.enable_sensors(\n    camera_path="/World/humanoid/head/camera",\n    rgb=True,\n    depth=True,\n    semantic=True,\n    instance=True\n)\n\n# Collect data\nfor i in range(10000):\n    world.step()\n    \n    rgb = sd_helper.get_rgb()\n    depth = sd_helper.get_depth()\n    semantic = sd_helper.get_semantic_segmentation()\n    \n    # Save for training\n    save_data(rgb, depth, semantic, f"frame_{i}")\n')),(0,r.yg)("h2",{id:"sim-to-real-transfer"},"Sim-to-Real Transfer"),(0,r.yg)("h3",{id:"domain-randomization"},"Domain Randomization"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'from omni.isaac.core.utils.prims import get_prim_at_path\nfrom pxr import UsdShade\n\n# Randomize lighting\nfor i in range(num_lights):\n    light_prim = get_prim_at_path(f"/World/Light_{i}")\n    light_prim.GetAttribute("intensity").Set(random.uniform(500, 3000))\n    \n# Randomize materials\nfor obj in scene_objects:\n    material = UsdShade.Material.Get(stage, obj.material_path)\n    material.GetInput("roughness").Set(random.uniform(0.1, 0.9))\n    material.GetInput("metallic").Set(random.uniform(0.0, 1.0))\n    \n# Randomize robot dynamics\nrobot_prim = get_prim_at_path("/World/humanoid")\nfor joint in robot_prim.joints:\n    joint.friction = random.uniform(0.01, 0.1)\n    joint.damping = random.uniform(0.1, 1.0)\n')),(0,r.yg)("h2",{id:"cloud-deployment"},"Cloud Deployment"),(0,r.yg)("p",null,"Scale training with Isaac Sim on cloud:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"# Using NVIDIA NGC Containers\ndocker pull nvcr.io/nvidia/isaac-sim:2023.1.1\n\n# Run headless\ndocker run --gpus all -it \\\n  -v $(pwd)/workspace:/workspace \\\n  nvcr.io/nvidia/isaac-sim:2023.1.1 \\\n  /isaac-sim/python.sh /workspace/train_humanoid.py\n")),(0,r.yg)("h2",{id:"best-practices"},"Best Practices"),(0,r.yg)("blockquote",null,(0,r.yg)("p",{parentName:"blockquote"},"[!TIP]","\n",(0,r.yg)("strong",{parentName:"p"},"Start Simple"),": Begin with basic walking before attempting complex tasks like object manipulation.")),(0,r.yg)("blockquote",null,(0,r.yg)("p",{parentName:"blockquote"},"[!WARNING]","\n",(0,r.yg)("strong",{parentName:"p"},"GPU Memory"),": Isaac Sim + Isaac Gym can consume 20GB+ VRAM with large parallel environments.")),(0,r.yg)("blockquote",null,(0,r.yg)("p",{parentName:"blockquote"},"[!IMPORTANT]","\n",(0,r.yg)("strong",{parentName:"p"},"Sim-to-Real Gap"),": Always test trained policies in simulation with noise and randomization before deploying to real hardware.")),(0,r.yg)("h2",{id:"next-steps"},"Next Steps"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("a",{parentName:"strong",href:"/piaic-physical-ai-textbook/docs/physical-ai/module3-isaac/navigation"},"Navigation with Nav2"))," - Path planning for humanoids"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},(0,r.yg)("a",{parentName:"strong",href:"/piaic-physical-ai-textbook/docs/physical-ai/module4-vla/overview"},"Module 4: VLA"))," - Language-driven robot control")),(0,r.yg)("h2",{id:"resources"},"Resources"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://docs.omniverse.nvidia.com/isaacsim/latest/"},"Isaac Sim Docs")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://nvidia-isaac-ros.github.io/"},"Isaac ROS")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://developer.nvidia.com/isaac-gym"},"Isaac Gym")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://www.nvidia.com/en-us/omniverse/"},"Omniverse"))))}p.isMDXComponent=!0},5680:(e,a,n)=>{n.d(a,{xA:()=>m,yg:()=>g});var i=n(6540);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function t(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);a&&(i=i.filter(function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable})),n.push.apply(n,i)}return n}function o(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?t(Object(n),!0).forEach(function(a){r(e,a,n[a])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):t(Object(n)).forEach(function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))})}return e}function s(e,a){if(null==e)return{};var n,i,r=function(e,a){if(null==e)return{};var n,i,r={},t=Object.keys(e);for(i=0;i<t.length;i++)n=t[i],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);for(i=0;i<t.length;i++)n=t[i],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=i.createContext({}),c=function(e){var a=i.useContext(l),n=a;return e&&(n="function"==typeof e?e(a):o(o({},a),e)),n},m=function(e){var a=c(e.components);return i.createElement(l.Provider,{value:a},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return i.createElement(i.Fragment,{},a)}},u=i.forwardRef(function(e,a){var n=e.components,r=e.mdxType,t=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),p=c(n),u=r,g=p["".concat(l,".").concat(u)]||p[u]||d[u]||t;return n?i.createElement(g,o(o({ref:a},m),{},{components:n})):i.createElement(g,o({ref:a},m))});function g(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var t=n.length,o=new Array(t);o[0]=u;var s={};for(var l in a)hasOwnProperty.call(a,l)&&(s[l]=a[l]);s.originalType=e,s[p]="string"==typeof e?e:r,o[1]=s;for(var c=2;c<t;c++)o[c]=n[c];return i.createElement.apply(null,o)}return i.createElement.apply(null,n)}u.displayName="MDXCreateElement"}}]);